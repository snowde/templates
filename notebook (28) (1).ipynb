{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kagglegym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn libraries\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSo there are 111 columns present in the dataset.\\n1 id column\\n1 timestamp column\\n5 columns with name prefix 'derived'\\n63 columns with name prefix 'fundamental' - fundamental_0 to fundamental_63 - 'fundamental_4' is missing. Any specific reasons?\\n40 columns with name prefix 'technical' - technical_0 to technical_44 - technical_4, technical_8, technical_15, technical_23, technical_26 are missing.\\n1 target variable named 'y'\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "environment = kagglegym.make() # This creates an environment in the API for me to play in\n",
    "observation = environment.reset() # Resets to first observations \"view of what you can see presently\"\n",
    "\n",
    "excl = [environment.ID_COL_NAME, environment.TARGET_COL_NAME, environment.TIME_COL_NAME,\n",
    "environment.SAMPLE_COL_NAME]\n",
    "col = [c for c in observation.train.columns if c not in excl]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "df_old = observation.train\n",
    "df = df_old[(np.abs(stats.zscore(df_old[\"y\"])) < 3.6)]\n",
    "#df = observation.train\n",
    "df_full = pd.read_hdf('../input/train.h5')\n",
    "d_mean= df[col].median(axis=0)\n",
    "\n",
    "\n",
    "min_y = df[\"y\"].min()\n",
    "max_y = df[\"y\"].max()\n",
    "print (min_y, max_y)\n",
    "\n",
    "X_train =df[col]\n",
    "n = X_train.isnull().sum(axis=1)\n",
    "\n",
    "for c in col: \n",
    "    r = pd.isnull(X_train.loc[:, c])\n",
    "    X_train[c + '_nan_'] = r  \n",
    "    d_mean[c + '_nan_'] = 0                                     \n",
    "\n",
    "X_train = X_train.fillna(d_mean)\n",
    "df = df.fillna(d_mean)\n",
    "X_train['znull'] = n \n",
    "n = []\n",
    "\n",
    "\"\"\"\n",
    "So there are 111 columns present in the dataset.\n",
    "1 id column\n",
    "1 timestamp column\n",
    "5 columns with name prefix 'derived'\n",
    "63 columns with name prefix 'fundamental' - fundamental_0 to fundamental_63 - 'fundamental_4' is missing. Any specific reasons?\n",
    "40 columns with name prefix 'technical' - technical_0 to technical_44 - technical_4, technical_8, technical_15, technical_23, technical_26 are missing.\n",
    "1 target variable named 'y'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of rows: {}, Number of columns: {}'.format(*df.shape))\n",
    "\n",
    "cols = [0, 0, 0]\n",
    "for c in df.columns:\n",
    "    if 'derived' in c: cols[0] += 1\n",
    "    if 'fundamental' in c: cols[1] += 1\n",
    "    if 'technical' in c: cols[2] += 1\n",
    "print('Derived columns: {}, Fundamental columns: {}, Technical columns: {}'.format(*cols))\n",
    "print('\\nColumn dtypes:')\n",
    "print(df.dtypes.value_counts())\n",
    "print('\\nint16 columns:')\n",
    "print(df.columns[train_one.dtypes == 'int16'])\n",
    "yellow = [len(df.id.unique()), len(df.timestamp.unique()) ]\n",
    "print('We are tracking {} unique assets over {} periods.'.format(*yellow))\n",
    "\n",
    "\n",
    "# I love this piece of code, it gives you a quick count of the type of columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have 1,424 assets that we are tracking across 1,813 time periods. We can't make any assumptions about the time period length - it could be days, hours, minutes, etc. as long as the period is uniform.\n",
    "The set of assets could be considered as the market portfolio. It would be interesting to see if these assets could be grouped into classes based on the observed data and features. For example, asset classes may be equities, bonds, etc.\n",
    "One approach may be to determine market return for a specific time period, and based on that predict the expected return of each asset based on autocorrelation and on how the asset returns correlate to market returns, given an asset class and other features.\n",
    "For now let's try to visualize the market return over the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Wow, this is some of the most beautiful code that I have seen in a long time\n",
    "\n",
    "market_df = df_full[['timestamp', 'y']].groupby('timestamp').agg([np.mean, np.std, len]).reset_index()\n",
    "market_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t      = market_df['timestamp']\n",
    "y_mean = np.array(market_df['y']['mean'])\n",
    "y_std  = np.array(market_df['y']['std'])\n",
    "n      = np.array(market_df['y']['len'])\n",
    "\n",
    "# These scatter plots are very similar to the histograms that I have further down. \n",
    "\n",
    "# This one below shows similar information to what I already have somewhere else. \n",
    "plt.figure()\n",
    "plt.plot(t, y_mean, '.')\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('mean of y')\n",
    "\n",
    "# Std shows a similar picture to the one above. \n",
    "plt.figure()\n",
    "plt.plot(t, y_std, '.')\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('std of y')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, n, '.')\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('portfolio size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like two periods of high variance that are correlated with rapid increases in the number of assets. The number of assets being tracked increases from 750 in the first timestamp to just under 1100 in the last.\n",
    "The total number of assets across all timestamps is 1424, so some assets are being dropped as well. It looks like assets are added to the portfolio periodically (see the gaps in the chart), and sold off more slowly.\n",
    "Let's derive a price chart for these returns. We can take the log of the periodic mean returns and get a cumulative sum for each time period to derive a fairly good approximation of a price chart for the portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Of course this makes sense they provided ius with a portfolio of stocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=-3\n",
    "y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cum_ret = np.log(1+y_mean).cumsum()\n",
    "\n",
    "#ln(1+ret) = is going to give you return. \n",
    "\n",
    "# log(1 + r_i) = log(\\frac{p_i}{p_j}) = \\log(p_i) - log(p_j) \n",
    "\n",
    "\n",
    "#cum_ret = np.array(1+y_mean)*(y_mean[-n]).cumsum()\n",
    "#fuck yea nb, go length for for loop, if you do not want ot go into the elements.\n",
    "# Even more important range seems to be the important one\n",
    "\n",
    "#for n in range(len(y_mean)):\n",
    "#    cum_new = (1+y_mean[n])*(y_mean[n+1])\n",
    "\n",
    "# This above is definitely wrong.\n",
    "#.cumsum()\n",
    "#cum_ret\n",
    "cum_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(t, cum_ret)\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('portfolio value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the log returns and adding them up is a good approximation for the compounding of returns.\n",
    "I tried the right method, but I fucked it up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(t, y_mean)\n",
    "plt.xlabel('timestamp')\n",
    "plt.ylabel('portfolio value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets_df = df.groupby('id')['y'].agg(['mean','std',len]).reset_index()\n",
    "assets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets_df = assets_df.sort_values(by='mean')\n",
    "assets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like individual asset returns range from a min of -0.035077 to a high of 0.010827, with a mean return of 0.000186 and a std dev of 0.001884.\n",
    "Assets have a mean holding period of roughly 1201 periods with a std dev of 646 periods, with a min holding period of 2 and a max of 1813 (all periods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(assets_df['mean'], rug=True, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assets_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(assets_df, vars=[\"mean\", \"std\", \"len\"])\n",
    "g = g.map_diag(plt.hist)\n",
    "g = g.map_offdiag(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be some interesting relationships here. Notably, mean asset returns and holding period are negatively correlated with the std dev of returns.\n",
    "Thanks for visiting! Next I'm going to look at time series of individual asset return and correlation with the portfolio returns...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = df.iloc[:,2:-1].corrwith(df.y)\n",
    "print('max_correlation', corr.max().max())\n",
    "print('min_correlation', corr.min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('id').size().hist(bins=500)\n",
    "# This shows you how much timestamps there is per id.\n",
    "# Remember that there is about 1000 unique ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is actually so weitd that there is that many for each.\n",
    "df_full.groupby('id').size().value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It seems that stuff that I cut away took a lot of the frequent occuring\n",
    "# assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('id').size().value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = df_full.groupby('id').size()\n",
    "print(len(size), max(size))\n",
    "assets = size[size==1813].index.values\n",
    "print(len(assets))\n",
    "\n",
    "correlations = pd.DataFrame()\n",
    "\n",
    "for asset in assets:\n",
    "    \n",
    "    df2 = df_full[df_full.id==asset]\n",
    "    corr = df2.drop(['id', 'timestamp', 'y'], axis=1).corrwith(df2.y)\n",
    "    correlations[asset] = corr\n",
    "\n",
    "correlations.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that NaN values are present in all columns but two  (tech_22 & 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,15))\n",
    "sns.heatmap(correlations, vmin=-0.22, vmax=0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reward(y_true, y_fit):\n",
    "    R2 = 1 - np.sum((y_true - y_fit)**2) / np.sum((y_true - np.mean(y_true))**2)\n",
    "    R = np.sign(R2) * math.sqrt(abs(R2))\n",
    "    return(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some pre-processing as seen from most of the public scripts.\n",
    "# The \"environment\" is our interface for code competitions\n",
    "\n",
    "# observation = env.reset()\n",
    "\n",
    "# We get our initial observation by calling \"reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation = environment.reset()\n",
    "cols_to_use_one = ['technical_20']\n",
    "\n",
    "# model build\n",
    "rid = Ridge()\n",
    "fit_three = rid.fit(np.array(df[cols_to_use].values), df[\"y\"].values)\n",
    "\n",
    "# getting the y mean dict for averaging\n",
    "ymean_dict = dict(observation.train.groupby([\"id\"])[\"y\"].mean())\n",
    "\n",
    "# weighted average of model & mean\n",
    "def get_weighted_y(series):\n",
    "    id, y = series[\"id\"], series[\"y\"]\n",
    "    return 0.95 * y + 0.05 * ymean_dict[id] if id in ymean_dict else y\n",
    "\n",
    "y_actual_list = []\n",
    "y_pred_list = []\n",
    "r1_overall_reward_list = []\n",
    "ts_list = []\n",
    "while True:\n",
    "    timestamp = observation.features[\"timestamp\"][0]\n",
    "    actual_y = list(df_full[df_full[\"timestamp\"] == timestamp][\"y\"].values)\n",
    "    observation.features.fillna(d_mean, inplace=True)\n",
    "    test_x = np.array(observation.features[cols_to_use].values)\n",
    "    observation.target.y = fit_three.predict(test_x).clip(min_y, max_y)\n",
    "    \n",
    "    ## weighted y using average value\n",
    "    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n",
    "    target = observation.target\n",
    "    observation, reward, done, info = environment.step(target)\n",
    "    \n",
    "    if timestamp % 100 == 0:\n",
    "        print(\"Timestamp #{}\".format(timestamp))\n",
    "    \n",
    "    pred_y = list(target.y.values)\n",
    "    y_actual_list.extend(actual_y)\n",
    "    y_pred_list.extend(pred_y)\n",
    "    overall_reward = get_reward(np.array(y_actual_list), np.array(y_pred_list))\n",
    "    r1_overall_reward_list.append(overall_reward)\n",
    "    ts_list.append(timestamp)\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(info)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(ts_list, r1_overall_reward_list, c='blue')\n",
    "plt.plot(ts_list, [0]*len(ts_list), c='red')\n",
    "plt.title(\"Cumulative R value change for Univariate Ridge (technical_20)\")\n",
    "plt.ylim([-0.04,0.04])\n",
    "plt.xlim([850, 1850])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observation = environment.reset()\n",
    "cols_to_use_two = ['technical_20', 'technical_30', 'fundamental_15'] \n",
    "# model build\n",
    "rid = Ridge()\n",
    "fit_four = rid.fit(np.array(df[cols_to_use_two].values), df[\"y\"].values)\n",
    "\n",
    "# getting the y mean dict for averaging\n",
    "ymean_dict = dict(observation.train.groupby([\"id\"])[\"y\"].mean())\n",
    "\n",
    "# weighted average of model & mean\n",
    "def get_weighted_y(series):\n",
    "    id, y = series[\"id\"], series[\"y\"]\n",
    "    return 0.95 * y + 0.05 * ymean_dict[id] if id in ymean_dict else y\n",
    "\n",
    "y_actual_list = []\n",
    "y_pred_list = []\n",
    "r3_overall_reward_list = []\n",
    "ts_list = []\n",
    "while True:\n",
    "    timestamp = observation.features[\"timestamp\"][0]\n",
    "    actual_y = list(df_full[df_full[\"timestamp\"] == timestamp][\"y\"].values)\n",
    "    observation.features.fillna(d_mean, inplace=True)\n",
    "    test_x = np.array(observation.features[cols_to_use_two].values)\n",
    "    observation.target.y = fit_four.predict(test_x).clip(min_y, max_y)\n",
    "    \n",
    "    ## weighted y using average value\n",
    "    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n",
    "    target = observation.target\n",
    "    observation, reward, done, info = environment.step(target)\n",
    "    \n",
    "    if timestamp % 100 == 0:\n",
    "        print(\"Timestamp #{}\".format(timestamp))\n",
    "    \n",
    "    pred_y = list(target.y.values)\n",
    "    y_actual_list.extend(actual_y)\n",
    "    y_pred_list.extend(pred_y)\n",
    "    overall_reward = get_reward(np.array(y_actual_list), np.array(y_pred_list))\n",
    "    r3_overall_reward_list.append(overall_reward)\n",
    "    ts_list.append(timestamp)\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
