{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it goes\n",
    "\n",
    " First sequential is an MLP model. I used it previously and it performed rather good. \n",
    " Now we will combine this with a convolutional neural network on the images\n",
    "\n",
    "Convolutional Neural Networks are MLPs with a special structure. \n",
    "\n",
    "CNNs have repetitive blocks of neurons that are applied across space (for images) or time (for audio signals etc). For images, these blocks of neurons can be interpreted as 2D convolutional kernels, repeatedly applied over each patch of the image. For speech, they can be seen as the 1D convolutional kernels applied across time-windows. At training time, the weights for these repeated blocks are 'shared', i.e. the weight gradients learned over various image patches are averaged. \n",
    "\n",
    "The reason for choosing this special structure, is to exploit spatial or temporal invariance in recognition. For instance, a \"dog\" or a \"car\" may appear anywhere in the image. If we were to learn independent weights at each spatial or temporal location, it would take orders of magnitude more training data to train such an MLP. In over-simplified terms, for an MLP which didn't repeat weights across space, the group of neurons receiving inputs from the lower left corner of the image will have to learn to represent \"dog\" independently from the group of neurons connected to upper left corner, and correspondingly we will need enough images of dogs such that the network had seen several examples of dogs at each possible image location separately.\n",
    "\n",
    "On top of this fundamental constraint, many special techniques and layers have been invented specially in the CNN context. So a latest deep CNN might look very different from a bare bones MLP, but the above is the difference in principle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikitlearn Libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Keras Libraries\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Custom \n",
    "# Variable decleration. \n",
    "\n",
    "root = '..\\input'\n",
    "np.random.seed(2016)\n",
    "split_random_state = 7\n",
    "split = .9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below you are offered a switch on standardisation. \n",
    "# We start off with a function for loading training data.\n",
    "\n",
    "def load_numeric_training(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the training data\n",
    "    and returns a tuple of the image ids, the data, and the labels\n",
    "    \"\"\"\n",
    "    # Read data from the CSV file\n",
    "    # Pop actually does something more interesting, it also deletes the\n",
    "    # from the dataframe. \n",
    "    \n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    # This below populates the variable with one column and drops the rest\n",
    "    ID = train.pop('id')\n",
    "    \n",
    "\n",
    "    # Since the labels are textual, so we encode them categorically\n",
    "    y = train.pop('species')\n",
    "    # Fit is to read in the data into the encoder\n",
    "    # Tranform is to do the actual encoding\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    \n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    # standardScaler seems to follow the same formatting as labelEncoder\n",
    "    X = StandardScaler().fit(train).transform(train) if standardize else train.values\n",
    "\n",
    "    # Below is a tuple that has to be accepted in that order \n",
    "    \n",
    "    return ID, X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.007812,  0.023438,  0.023438, ...,  0.004883,  0.      ,\n",
       "         0.025391],\n",
       "       [ 0.005859,  0.      ,  0.03125 , ...,  0.000977,  0.039062,\n",
       "         0.022461],\n",
       "       [ 0.005859,  0.009766,  0.019531, ...,  0.      ,  0.020508,\n",
       "         0.00293 ],\n",
       "       ..., \n",
       "       [ 0.001953,  0.003906,  0.      , ...,  0.027344,  0.      ,\n",
       "         0.001953],\n",
       "       [ 0.      ,  0.      ,  0.046875, ...,  0.      ,  0.001953,\n",
       "         0.00293 ],\n",
       "       [ 0.023438,  0.019531,  0.03125 , ...,  0.023438,  0.025391,\n",
       "         0.022461]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------- Code not needed testing. \n",
    "ID, X, y = load_numeric_training(standardize=False)\n",
    "X\n",
    "# The array looks just like a spreadsheet will look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ls', '../input']' returned non-zero exit status 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19e3371df3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Below you are offered a switch on standardisation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/subprocess.pyc\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ls', '../input']' returned non-zero exit status 1"
     ]
    }
   ],
   "source": [
    "# Next we have a function for loading testing data.\n",
    "\n",
    "def load_numeric_test(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the test data\n",
    "    and returns a tuple of the image ids, the data\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(\"input/test.csv\")\n",
    "    ID = test.pop('id')\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
    "    return ID, test\n",
    "\n",
    "\n",
    "# Below looks like the resiation of one image. \n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    \"\"\"\n",
    "    Resize the image to so the maximum side is of size max_dim\n",
    "    Returns a new image of the right size\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    # Recall that lambda is a throw-away, one-time, function \n",
    "    # Return the largest item in an iterable or the largest of two or more arguments.\n",
    "    # 0,1 is the arguments you pass it, 0 is height, 1 is width. \n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    # This means that the proportional dimensions remain the same. \n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_image_data(ids, max_dim=96, center=True):\n",
    "    \"\"\"\n",
    "    Takes as input an array of image ids and loads the images as numpy\n",
    "    arrays with the images resized so the longest side is max-dim length.\n",
    "    If center is True, then will place the image in the center of\n",
    "    the output array, otherwise it will be placed at the top-left corner.\n",
    "    \"\"\"\n",
    "    # Initialize the output array\n",
    "    # NOTE: Theano users comment line below and\n",
    "    # Return a new array of given shape and type, without initializing entries.\n",
    "    # According to me this has 4 dimensions? \n",
    "    # You do get something like a multi-dimensional array. \n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n",
    "    # emumerate gives the real id and a number of the id.\n",
    "    \n",
    "    for i, idee in enumerate(ids):\n",
    "        # Turn the image into an array\n",
    "        x = resize_img(load_img(os.path.join('images/', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        # img to array is an existing method part of keras.\n",
    "        # img has been resized but it has to put into array format. \n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        # NOTE: Theano users comment the two lines below and\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        # length = x.shape[1] # uncomment this\n",
    "        # width = x.shape[2] # uncomment this\n",
    "        if center:\n",
    "            # have to put into int for shape to understand. \n",
    "            # This is the code to position it to center\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            # Now it will be left in the hoek\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        # Insert into image matrix\n",
    "        # NOTE: Theano users comment line below and\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n",
    "    # Scale the array values so they are between 0 and 1\n",
    "    # It then rounds to a certain amount of decimals. \n",
    "    # Somehow they knew what the largest size was and they used this\n",
    "    return np.around(X / 255.0)\n",
    "\n",
    "# We only do the cross-validation on training data. \n",
    "\n",
    "def load_train_data(split=split, random_state=None):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image training data and\n",
    "    splits them into training and cross-validation.\n",
    "    Returns one tuple for the training data and one for the validation\n",
    "    data. Each tuple is in the order pre-extracted features, images,\n",
    "    and labels.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_tr, y = load_numeric_training()\n",
    "    # Load the image data\n",
    "    X_img_tr = load_image_data(ID)\n",
    "    # Split them into validation and cross-validation\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
    "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
    "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
    "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
    "   \n",
    "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image test data.\n",
    "    Returns a tuple in the order ids, pre-extracted features,\n",
    "    and images.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_te = load_numeric_test()\n",
    "    # Load the image data\n",
    "    X_img_te = load_image_data(ID)\n",
    "    return ID, X_num_te, X_img_te\n",
    "\n",
    "print('Loading the training data...')\n",
    "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "print('Training data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Augmenter...\n",
      "Finished making data augmenter...\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------- Data augmentation\n",
    "# This taks inludes random image rotation and zoom\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "\n",
    "# A little hacky piece of code to get access to the indices of the images...\n",
    "# ...the data augmenter is working with.\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(\n",
    "            X, y, self,\n",
    "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "            dim_ordering=self.dim_ordering,\n",
    "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):\n",
    "    def next(self):\n",
    "        # for python 2.x.\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch\n",
    "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
    "        with self.lock:\n",
    "            # We changed index_array to self.index_array\n",
    "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock so it can be done in parallel\n",
    "        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n",
    "        for i, j in enumerate(self.index_array):\n",
    "            x = self.X[j]\n",
    "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        if self.save_to_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=current_index + i,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y[self.index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "print('Creating Data Augmenter...')\n",
    "imgen = ImageDataGenerator2(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
    "print('Finished making data augmenter...')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For basic neural network architectures we can use Keras's Sequential API, but since we need to build a model that takes two different inputs (image and pre-extracted features) in two different locations in the model, we won't be able to use the Sequential API. Instead, we'll be using the Functional API. This API is just as straightforward, but instead of having a model we add layers to, we'll instead be passing an array through a layer, and passing that output through another layer, and so on. You can think of each layer as a function and the array we give it as its argument. Click here for more info about the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Model created!\n"
     ]
    }
   ],
   "source": [
    "#---------------------------Combining the Image CNN with the Pre-Extracted Features MLP¶\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, merge\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "\n",
    "    # Define the image input\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # Pass it through the first convolutional layer\n",
    "    x = Convolution2D(8, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Now through the second convolutional layer\n",
    "    x = (Convolution2D(32, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = merge([x, numerical], mode='concat')\n",
    "\n",
    "    # Add a fully connected layer just like in a normal MLP\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "model = combined_model()\n",
    "print('Model created!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're finally ready to actually train the model! Running on Kaggle will take a while. It's MUCH faster to run it locally if you have a GPU, or on an AWS instance with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 00000: val_loss improved from inf to 0.00039, saving model to leafnet.h5\n",
      "Epoch 00001: val_loss improved from 0.00039 to 0.00037, saving model to leafnet.h5\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 00007: val_loss improved from 0.00037 to 0.00025, saving model to leafnet.h5\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 00028: val_loss improved from 0.00025 to 0.00022, saving model to leafnet.h5\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 00034: val_loss improved from 0.00022 to 0.00010, saving model to leafnet.h5\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 00045: val_loss improved from 0.00010 to 0.00008, saving model to leafnet.h5\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 00064: val_loss did not improve\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 00068: val_loss did not improve\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 00088: val_loss did not improve\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 00092: val_loss did not improve\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 00098: val_loss did not improve\n",
      "Epoch 00099: val_loss did not improve\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 00105: val_loss did not improve\n",
      "Epoch 00106: val_loss did not improve\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 00113: val_loss did not improve\n",
      "Epoch 00114: val_loss improved from 0.00008 to 0.00006, saving model to leafnet.h5\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 00117: val_loss did not improve\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 00121: val_loss did not improve\n",
      "Epoch 00122: val_loss did not improve\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 00125: val_loss did not improve\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 00127: val_loss did not improve\n",
      "Epoch 00128: val_loss did not improve\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b076db4b6a04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                               \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_num_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                               callbacks=[best_model])\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading the best model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1449\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1450\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1452\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dereksnow/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X):\n",
    "    \"\"\"\n",
    "    A generator to train our keras neural network. It\n",
    "    takes the image augmenter generator and the array\n",
    "    of the pre-extracted features.\n",
    "    It yields a minibatch and will run indefinitely\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get the image batch and labels\n",
    "            batch_img, batch_y = next(imgen)\n",
    "            # This is where that change to the source code we\n",
    "            # made will come in handy. We can now access the indicies\n",
    "            # of the images that imgen gave us.\n",
    "            x = X[imgen.index_array]\n",
    "            yield [batch_img, x], batch_y\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"leafnet.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=1000,\n",
    "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model])\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## we need to consider the loss for final submission to leaderboard\n",
    "## print(history.history.keys())\n",
    "print('val_acc: ',max(history.history['val_acc']))\n",
    "print('val_loss: ',min(history.history['val_loss']))\n",
    "print('train_acc: ',max(history.history['acc']))\n",
    "print('train_loss: ',min(history.history['loss']))\n",
    "\n",
    "print()\n",
    "print(\"train/val loss ratio: \", min(history.history['loss'])/min(history.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "## Plotting the loss with the number of iterations\n",
    "\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting the error with the number of iterations\n",
    "## With each iteration the error reduces smoothly\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and writing submission...\n",
      "Finished writing submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>9.732460e-23</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.580490e-22</td>\n",
       "      <td>2.918674e-21</td>\n",
       "      <td>1.475046e-11</td>\n",
       "      <td>4.965136e-21</td>\n",
       "      <td>1.489809e-29</td>\n",
       "      <td>2.351745e-19</td>\n",
       "      <td>5.251790e-16</td>\n",
       "      <td>8.054925e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.448120e-29</td>\n",
       "      <td>2.640295e-29</td>\n",
       "      <td>1.381857e-31</td>\n",
       "      <td>6.660142e-23</td>\n",
       "      <td>4.477618e-32</td>\n",
       "      <td>1.034051e-25</td>\n",
       "      <td>2.274980e-24</td>\n",
       "      <td>7.207536e-32</td>\n",
       "      <td>2.902506e-30</td>\n",
       "      <td>1.728592e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>3.179354e-21</td>\n",
       "      <td>2.761599e-19</td>\n",
       "      <td>1.428463e-28</td>\n",
       "      <td>4.436568e-12</td>\n",
       "      <td>3.785086e-25</td>\n",
       "      <td>9.450088e-32</td>\n",
       "      <td>8.500857e-23</td>\n",
       "      <td>1.481659e-14</td>\n",
       "      <td>1.648460e-12</td>\n",
       "      <td>1.940630e-24</td>\n",
       "      <td>...</td>\n",
       "      <td>8.929313e-21</td>\n",
       "      <td>6.713418e-26</td>\n",
       "      <td>1.783730e-11</td>\n",
       "      <td>3.478057e-18</td>\n",
       "      <td>5.390251e-10</td>\n",
       "      <td>4.342291e-09</td>\n",
       "      <td>1.477519e-17</td>\n",
       "      <td>1.087486e-18</td>\n",
       "      <td>8.494681e-27</td>\n",
       "      <td>1.845044e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1.929810e-14</td>\n",
       "      <td>8.584706e-23</td>\n",
       "      <td>3.179017e-27</td>\n",
       "      <td>1.185202e-24</td>\n",
       "      <td>2.478193e-19</td>\n",
       "      <td>3.264831e-16</td>\n",
       "      <td>1.233863e-34</td>\n",
       "      <td>4.201948e-20</td>\n",
       "      <td>3.336759e-26</td>\n",
       "      <td>1.137493e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.611348e-35</td>\n",
       "      <td>2.137328e-29</td>\n",
       "      <td>9.296880e-23</td>\n",
       "      <td>4.154239e-23</td>\n",
       "      <td>4.602525e-20</td>\n",
       "      <td>8.577914e-34</td>\n",
       "      <td>4.263994e-31</td>\n",
       "      <td>6.403094e-22</td>\n",
       "      <td>2.787292e-22</td>\n",
       "      <td>1.259395e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1.540434e-22</td>\n",
       "      <td>5.426165e-19</td>\n",
       "      <td>7.103119e-21</td>\n",
       "      <td>1.770784e-15</td>\n",
       "      <td>1.507297e-19</td>\n",
       "      <td>2.437834e-29</td>\n",
       "      <td>8.464697e-19</td>\n",
       "      <td>8.985027e-13</td>\n",
       "      <td>2.677789e-18</td>\n",
       "      <td>1.005978e-26</td>\n",
       "      <td>...</td>\n",
       "      <td>3.181805e-21</td>\n",
       "      <td>2.801440e-20</td>\n",
       "      <td>3.111767e-34</td>\n",
       "      <td>2.949946e-12</td>\n",
       "      <td>2.936691e-27</td>\n",
       "      <td>1.104438e-19</td>\n",
       "      <td>4.946997e-24</td>\n",
       "      <td>1.722264e-16</td>\n",
       "      <td>4.367362e-30</td>\n",
       "      <td>2.977807e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.794486e-23</td>\n",
       "      <td>3.849859e-25</td>\n",
       "      <td>5.476025e-28</td>\n",
       "      <td>8.038132e-25</td>\n",
       "      <td>6.674886e-18</td>\n",
       "      <td>4.537171e-20</td>\n",
       "      <td>6.503471e-25</td>\n",
       "      <td>1.648464e-29</td>\n",
       "      <td>7.302382e-31</td>\n",
       "      <td>...</td>\n",
       "      <td>6.600870e-26</td>\n",
       "      <td>6.455269e-34</td>\n",
       "      <td>9.636244e-34</td>\n",
       "      <td>1.585682e-28</td>\n",
       "      <td>4.156420e-26</td>\n",
       "      <td>1.464748e-30</td>\n",
       "      <td>5.361583e-32</td>\n",
       "      <td>9.176537e-34</td>\n",
       "      <td>3.752899e-38</td>\n",
       "      <td>9.067588e-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "id                                                                   \n",
       "1576     9.732460e-23     1.000000e+00  7.580490e-22  2.918674e-21   \n",
       "1577     3.179354e-21     2.761599e-19  1.428463e-28  4.436568e-12   \n",
       "1579     1.929810e-14     8.584706e-23  3.179017e-27  1.185202e-24   \n",
       "1580     1.540434e-22     5.426165e-19  7.103119e-21  1.770784e-15   \n",
       "1583     0.000000e+00     4.794486e-23  3.849859e-25  5.476025e-28   \n",
       "\n",
       "      Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "id                                                                 \n",
       "1576   1.475046e-11  4.965136e-21     1.489809e-29  2.351745e-19   \n",
       "1577   3.785086e-25  9.450088e-32     8.500857e-23  1.481659e-14   \n",
       "1579   2.478193e-19  3.264831e-16     1.233863e-34  4.201948e-20   \n",
       "1580   1.507297e-19  2.437834e-29     8.464697e-19  8.985027e-13   \n",
       "1583   8.038132e-25  6.674886e-18     4.537171e-20  6.503471e-25   \n",
       "\n",
       "      Acer_Rufinerve  Acer_Saccharinum       ...         Salix_Fragilis  \\\n",
       "id                                           ...                          \n",
       "1576    5.251790e-16      8.054925e-17       ...           1.448120e-29   \n",
       "1577    1.648460e-12      1.940630e-24       ...           8.929313e-21   \n",
       "1579    3.336759e-26      1.137493e-14       ...           6.611348e-35   \n",
       "1580    2.677789e-18      1.005978e-26       ...           3.181805e-21   \n",
       "1583    1.648464e-29      7.302382e-31       ...           6.600870e-26   \n",
       "\n",
       "      Salix_Intergra   Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  \\\n",
       "id                                                                      \n",
       "1576    2.640295e-29  1.381857e-31   6.660142e-23        4.477618e-32   \n",
       "1577    6.713418e-26  1.783730e-11   3.478057e-18        5.390251e-10   \n",
       "1579    2.137328e-29  9.296880e-23   4.154239e-23        4.602525e-20   \n",
       "1580    2.801440e-20  3.111767e-34   2.949946e-12        2.936691e-27   \n",
       "1583    6.455269e-34  9.636244e-34   1.585682e-28        4.156420e-26   \n",
       "\n",
       "      Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "id                                                          \n",
       "1576     1.034051e-25        2.274980e-24    7.207536e-32   \n",
       "1577     4.342291e-09        1.477519e-17    1.087486e-18   \n",
       "1579     8.577914e-34        4.263994e-31    6.403094e-22   \n",
       "1580     1.104438e-19        4.946997e-24    1.722264e-16   \n",
       "1583     1.464748e-30        5.361583e-32    9.176537e-34   \n",
       "\n",
       "      Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "id                                                   \n",
       "1576                  2.902506e-30     1.728592e-13  \n",
       "1577                  8.494681e-27     1.845044e-15  \n",
       "1579                  2.787292e-22     1.259395e-18  \n",
       "1580                  4.367362e-30     2.977807e-21  \n",
       "1583                  3.752899e-38     9.067588e-26  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names of the column headers\n",
    "LABELS = sorted(pd.read_csv(\"input/train.csv\").species.unique())\n",
    "\n",
    "index, test, X_img_te = load_test_data()\n",
    "\n",
    "yPred_proba = model.predict([X_img_te, test])\n",
    "\n",
    "# Converting the test predictions in a dataframe as depicted by sample submission\n",
    "yPred = pd.DataFrame(yPred_proba,index=index,columns=LABELS)\n",
    "\n",
    "print('Creating and writing submission...')\n",
    "fp = open('submit.csv', 'w')\n",
    "fp.write(yPred.to_csv())\n",
    "print('Finished writing submission')\n",
    "# Display the submission\n",
    "yPred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
